DONE:
  get latex to run
  how did i modify ssdeep?
  reference to paper on spamsum, differences to ssdeep
  reference ppdeep: ssdeep like hashing method in pure python https://github.com/elceef/ppdeep
  reference framework and test-set repos
  Q: wallet types: how where the types assigned? what do they mean? does same type mean same sol code?
  ref pyLZJD paper
  use roman numerals for sections
  test spec
  flow and order
  ref sections in test spec
  similarity measures
  test spec methods: mention similarity measure used
  similarity: mention with what digests they are used
  wallets i only used codes with unique skeletons
  Synthetix diff table
  conclusion keywords
  remarks keywords
  red todo's
FIRST:
TODO:
  conclusion
  describe O R H C I
  https://www.ethervm.io/ opcodes
  https://etherscan.io/bytecode-decompiler?a=0x4a8eae10b7ee97a2c6a6212776f059a25e90e7f4
  corelation matrix (kendall)
LATER:
  mention another fuzzy hashing paper in the introduction
  example digest for all methods
  in order to show
    wallets solcOption and smallGroupByAbi have same results
    separation number corresponds to scatter impression
  show that
    bytebag is better than size
    unfiltered ssdeep is not better bytebag
    lzjd is not better than filtered byteBag
    filtered ppdeep is better than byteBag
    filtered ppdeep is better than lzjd
    skel is better than raw for ppdeep and jump
    filtered is better than skel for ppdeep and jump
    filtered jump is better than filtered ppdeep
    filtered bz is better than filtered ppdeep
    filtered skeletons are better than raw for jump, bz and ppdeep
    raw bz is better than raw jump
    filtered bz is comparable to filtered jump
    filtering does not improve lzjd and ncd
    ncd is better than filtered ppdeep
    jump performs comparable to ncd
    wallets and solcOptions yield similar results
    smallGroupByAbi results don't conflict with wallets and solcOptions
    first code section is sufficient
    first code section is better than full skeleton
    optimization changes are bigger than version changes
    abi encoding change lowers hash scores
    jumpi is sufficient for block splitting
      optimization changes block splitting
        JUMP 0x56, RETURN 0xF3, STOP 0x00, REVERT 0xFD followed by JUMPDEST 0x5B
        (\x56|\xF3|\x00|\xFD)\\x5B#
    skel bz2 is best on solc
    reference pyPI packages?
  mention
    f-state on solcOptions is cheating because f-stat is based on solcOptions
    K hashes
    abi moved from front to back
    contracts have mostly on code section
    small overview of similarity measures
      explanation: what are they use for
      differences
      suitability: their results, why did I not use it, my results
  interesting numbers
    length of codes
    number of jumpi pre code
    length of jumpi chunks
    length of first section
    number of sections
  include
    reference the commit id when including results
    one big table of separations
    some scatters to trust separations
    one cluster
    one pair of source codes
MAYBE:
  section on time and space complexity
    wicherski2009pehash -> 1.1 Related Work
  test sdHash
  read about MRS hashing
    is in O(n)
  read about bbr
  mention Instruction n-grams
    filter some push pop instructions and leaf in less common instructions
FINALLY:
  use bibtex refs with web-links
NOTES:
  delete tmp files: git clean -Xf
  font
    %\fontfamily{lmtt}\selectfont
    %\sffamily
    %\renewcommand{\familydefault}{\sfdefault}
    %\emergencystretch 1pt
  install the following packages in tex-live
    latexmk
    ly1
    csquotes
    biber
    biblatex
    sourcodepro
    xkeyval
    listings
    parskip
    subfiles
    csvsimple
    pgf
    enumitem
    % glossary
    % notocondensed
    notomath
      noto
      fontaxes
      fontspec
    microtype
