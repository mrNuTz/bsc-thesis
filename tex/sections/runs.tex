\documentclass[../main.tex]{subfiles}
\begin{document}

\subsection{Comparison Tables of all Measures}

To get an overview, tables of all \n{qDists} and \n{Separations} are included (\n{wallets} \tblref{tbl:wallet_sep}, \n{\solcts} \tblref{tbl:solc_sep}, \n{smallGroupsByAbi} \tblref{tbl:smallGroupsByAbi}, \n{proxies} \tblref{tbl:proxies_sep}).

\begin{sepTbl}{wallets}{all}{\pdfmatch{fourbyte}{\csvcoli}=0 \or \pdfmatch{raw}{\csvcoli}=1}
  \caption{\n{wallet} dataset \n{qDists} and \n{separations}}
  \label{tbl:wallet_sep}
\end{sepTbl}

\begin{sepTbl}{solcOptions}{all}{\pdfmatch{fStat}{\csvcoli}=0}
  \caption{\n{\solcts} \n{qDists} and \n{separations}}
  \label{tbl:solc_sep}
\end{sepTbl}

\begin{sepTbl}{smallGroupsByAbi}{all}{\pdfmatch{fourbyte}{\csvcoli}=0}
  \caption{\n{smallGroupsByAbi} dataset \n{qDists} and \n{separations}}
  \label{tbl:smallGroupsByAbi}
\end{sepTbl}

\begin{sepTbl}{proxies}{all}{\pdfmatch{fourbyte}{\csvcoli}=0 \or \pdfmatch{raw}{\csvcoli}=1}
  \caption{\n{proxies} dataset \n{qDists} and \n{separations}}
  \label{tbl:proxies_sep}
\end{sepTbl}

\subsection{Chunk Splitting}
\begin{hyp}
  The universal chunk splitting of \n{ssdeep} can be improved with domain knowledge about \n{EVM} runtime codes.
\end{hyp}
\begin{res}
  Splitting by \code{JUMPI} achieves better results than the context trigger used by \n{ssdeep} \figref{fig:walletsJumpPpHist} \figref{fig:solcJumpPpHist}.
\end{res}

\begin{figure}[ht!]
  \centering
  \incHist{wallets}{all}{fStat}{ppdeep\_mod}{wallets}%
  \incHist{wallets}{all}{skeletons}{ppdeep\_mod}{wallets}%
  \incHist{wallets}{all}{fStat}{jump}{wallets}%
  \incHist{wallets}{all}{skeletons}{jump}{wallets}%
  \caption{\n{ppdeep\_mod} vs. \n{jump} on \n{wallets}}
  \label{fig:walletsJumpPpHist}
\end{figure}

\begin{figure}[ht!]
  \centering
  \incHist{solcOptions}{all}{skeletons}{ppdeep\_mod}{\solcts}%
  \incHist{solcOptions}{all}{fstSecSkel}{ppdeep\_mod}{\solcts}%
  \incHist{solcOptions}{all}{fstSecSkel}{jump}{\solcts}%
  \incHist{solcOptions}{all}{skeletons}{jump}{\solcts}%
  \caption{\n{ppdeep\_mod} vs. \n{jump} on \n{\solcts}}
  \label{fig:solcJumpPpHist}
\end{figure}

\begin{res}
  \code{JUMPI} has a higher f-statistic value than \code{JUMP}, \code{RETURN} and \code{JUMPDEST} \tblref{tbl:solcFstat}, because optimization removes the latter opcodes \tblref{tbl:opt_diff}.
  The chunk sizes obtained with \code{JUMPI} strike a good balance.
\end{res}
\begin{conc}
  Therefore \code{JUMPI} is a better splitter than patterns containing \code{JUMP}, \code{RETURN} or \code{JUMPDEST}.
\end{conc}

\subsection{Pre-Processing}
\begin{res}
  Chunk-hashes perform better on the skeleton of the first code section than on the whole code \figref{fig:wallPpJpSkelRaw}.
\end{res}
\begin{res}
  Filtering opcodes with \n{fStat} improves the results for \n{jump} and \n{bytebag} \figref{fig:fstSekVsFstatWallets}.
\end{res}

\begin{figure}[ht!]
  \centering
  \incHist{wallets}{all}{raw}{ppdeep\_mod}{wallets}%
  \incHist{wallets}{all}{fstSecSkel}{ppdeep\_mod}{wallets}%
  \incHist{wallets}{all}{raw}{jump}{wallets}%
  \incHist{wallets}{all}{fstSecSkel}{jump}{wallets}%
  \caption{\n{fstSecSkel} vs. \n{raw} on \n{wallets}}
  \label{fig:wallPpJpSkelRaw}
\end{figure}

\begin{figure}[ht!]
  \centering
  \incHist{wallets}{all}{fstSecSkel}{bytebag}{wallets}%
  \incHist{wallets}{all}{fStat}{bytebag}{wallets}%
  \incHist{wallets}{all}{fstSecSkel}{jump}{wallets}%
  \incHist{wallets}{all}{fStat}{jump}{wallets}%
  \caption{\n{bytebag} and \n{jump} with \n{fstSecSkel} vs. \n{fStat} on \n{wallets}}
  \label{fig:fstSekVsFstatWallets}
\end{figure}

\subsection{'K' Sequences}
\begin{obs}
  \n{ssdeep} and variants generate long sequences of 'K' chunk-hashes when hashing code skeletons.
  E.g. the contract \n{ACATokenSale} at \n{0xb68a47aee7b6b79d203125eece1eef8ff19cbf3e} results in the hash \n{192:fKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKS:fO9SSNFtZT}.
\end{obs}
\begin{res}
  \n{ppdeep\_mod} without sequence striping performs better than \n{ssdeep} and \n{ppdeep} \figref{fig:ssppScat}.
\end{res}
\begin{res}
  \n{Levenshtein} works better than \n{Jaccard} on \n{ssdeep} hashes, because \n{Jaccard} reduces the 'K' sequences to one entry.
\end{res}


\begin{figure}[ht!]
  \centering
  \incScatter{wallets}{all}{skeletons}{ssdeep}{skeletons}{ppdeep}{wallets}%
  \incScatter{wallets}{all}{skeletons}{ssdeep}{skeletons}{ppdeep\_mod}{wallets}
  \caption{Scatter plot of ppdeep and ssdeep similarity scores for all wallet code pairs}
  \label{fig:ssppScat}
\end{figure}

\subsection{NCD}
\begin{hyp}
  \n{ncd} is flexible, it deals with the short proxy codes and handles the biggest compile changes better than the other methods.
\end{hyp}
\begin{res}
  \n{ncd} comparison takes a long time, because all code-pairs need to be compressed together, i.e. \n{ncd} comparison is performed on the full codes and the other methods compare the much smaller digests, which are calculated only once for each code.
\end{res}

\subsection{Proxies}
\begin{res}
  On the short \n{proxy} codes, the chunk-hashes (\n{jump}, \n{ssdeep}, \n{ppdeep}, \n{bz}) performance poorly; the binary similarity measures (\n{bytebag}, \n{lev}, \n{ncd}, \n{lzjd}) show better results.
\end{res}

\subsection{Runtime}
\begin{obs}
  When comparing all to all codes hashing runtime becomes insignificant, the comparison of the hashes generally takes much longer, even thought individually comparisons are faster than hash calculations.
\end{obs}

\begin{figure}[ht!]
  \centering
  \incScatter{lzjdParams}{all}{raw}{ncd}{raw}{lzjd256}{\solcts}%
  \incScatter{solcOptions}{all}{raw}{ncd}{fstSecSkel}{jump}{\solcts}
  \caption{Scatter plots of \n{raw ncd} similarity scores for all \n{\solcts} code pairs vs. \n{raw lzjd} (left) and \n{fstSecSkel jump} (right).}
  \label{fig:ncdLzScat}
\end{figure}

\subsection{solc}
\begin{obs}
  Fourbyte signatures in the jump table at the beginning of all codes are sorted and the functions jumped to are sorted as well.
\end{obs}
\begin{obs}
  Optimization removes \code{JUMPDEST} opcodes.
\end{obs}
\begin{obs}
  Enabling optimization when compiling with \n{solc} causes bigger changes to the codes than switching \n{solc} version.
\end{obs}
\begin{obs}
  Optimization changes the how the ABI jump table is realized, solely causing significant changes for domain independent similarity measures.
\end{obs}
\begin{obs}
  Version changes are comparably smaller, but the default ABI encoding changed from v1 to v2 with solc version 0.8.0.
\end{obs}
\begin{res}
  \n{Levenshtein} works better than \n{Jaccard} with chunk-hashes, because \n{solc} orders functions by signature in the runtime code.
\end{res}

\subsection{jump}

\begin{res}
  Considering its simplicity \n{jump} performs surprisingly well, partially due to the fact that the number of \code{JUMPI} opcodes has a high \n{fStat} value.
\end{res}
\begin{res}
  \n{jump} correlates strongly with \n{ncd}, which seams to be more robust to optimization changes, but comparisons take 30 times longer and \n{jump} separates groups more sharply.
\end{res}
\begin{obs}
  The nativ Levenshtein implementation, used for comparison of \n{jump} and \n{bz} digests, is the fastest out of all hash similarities used in this work. Only Jaccard applied to the much shorter \n{fourbyte} signature sets is faster.
\end{obs}

\subsection{lzjd}

\begin{res}
  The similarity numbers for 'same' and 'cross' pairs look close \figref{fig:solc_lzjd1}\figref{fig:solc_lzjd2} but \n{raw lzjd} scores high in the \n{separation} and \n{qDist} comparison \tblref{tbl:wallet_sep}\tblref{tbl:solc_sep}.
\end{res}

\begin{figure}[ht!]
  \centering
  \incHist{lzjdParams}{all}{raw}{lzjd32}{\solcts}%
  \incHist{lzjdParams}{all}{raw}{lzjd64}{\solcts}%
  \incHist{lzjdParams}{all}{raw}{lzjd128}{\solcts}%
  \incHist{lzjdParams}{all}{raw}{ncd}{\solcts}%
  \caption{\n{lzjd[32,64,128]} on all \n{raw} \n{\solcts} codes}
  \label{fig:solc_lzjd1}
\end{figure}

\begin{figure}[ht!]
  \centering
  \incHist{lzjdParams}{all}{raw}{lzjd256}{\solcts}%
  \incHist{lzjdParams}{all}{raw}{lzjd512}{\solcts}%
  \incHist{lzjdParams}{all}{raw}{lzjd1K}{\solcts}%
  \incHist{solcOptions}{all}{raw}{bz}{\solcts}%
  \caption{\n{lzjd[256,512,1K]} on all \n{raw} \n{\solcts} codes}
  \label{fig:solc_lzjd2}
\end{figure}

\begin{res}
  \n{lzjd} works better with \n{raw} codes and 256 is a good default \n{hash\_size} setting \tblref{tbl:lz_solc_sep}\tblref{tbl:lz_wall_sep}\figref{fig:hist_wallets_lzjd}.
\end{res}

\begin{sepTbl}{lzjdParams}{all}{\pdfmatch{^(raw|skel) lzjd}{\csvcoli}=1}
  \caption{\n{lzjd} \n{qDists} and \n{separations} on all codes from \n{\solcts}}
  \label{tbl:lz_solc_sep}
\end{sepTbl}

\begin{figure}[ht!]
  \centering
  \incHist{wallets}{all}{raw}{lzjd}{wallets}%
  \incHist{wallets}{all}{skeletons}{lzjd}{wallets}%
  \incHist{wallets}{all}{fstSecSkel}{lzjd}{wallets}%
  \incHist{wallets}{all}{fStat0}{lzjd}{wallets}%
  \caption{\n{lzjd[256]} on \n{wallets} dataset with different pre-processing methods}
  \label{fig:hist_wallets_lzjd}
\end{figure}

\begin{sepTbl}{wallets}{all}{\pdfmatch{lzjd}{\csvcoli}=1}
  \caption{\n{lzjd} \n{qDists} and \n{separations} on all \n{wallet} codes}
  \label{tbl:lz_wall_sep}
\end{sepTbl}

\subsection{bytebag}
\begin{res}
  \n{Bytebag} is simple and fast, jet it seams to be a useful way to determine similarity.
\end{res}

\end{document}
