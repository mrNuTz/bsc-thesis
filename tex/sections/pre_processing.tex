\documentclass[../main.tex]{subfiles}
\begin{document}

\subsection{Segmentation}
Segmentation splits the codes into \code{code}, \code{data} and \code{meta} sections \cite{ethutils}.

\code{meta} sections have no effect on execution and change between compilations.

\code{data} sections are e.g. constructor arguments.
Constructor-arguments are deployed by the actual contract (first code-section).
Generally they're only used for parameter initialization and have no essential effect on the execution.
Limiting the possible effectiveness is the fact that detection is heuristic.

The first \code{code} section is the the actual contract, the other code-sections are in essence just data for the first-section, if it itself deploys further contracts.

\subsection{Skeletonization}
Skeletons are runtime codes where constructor arguments, data sections, meta sections and push arguments are set to zero \cite{ethutils}.
Contracts can be associated via skeletons, because many deployed codes have identical skeletons.
Push-operations are the only EVM-instructions followed by data.
The reasoning behind this removal is that, these data bytes have no essential effect on the execution, e.g. jump-addresses and ethereum-addresses.
Setting the push arguments to zero has the benefit of preserving the ability to disassemble the code.

\subsection{Opcode filtering}
The same externally observable behavior can be achieved via different opcode sequences.
Some opcodes are more likely to change with solc-versions or compile-options than others.
Removing less significant opcodes before hashing should yield more meaningful similarity scores.

\subsubsection{\code{fStat} Filter\cite{ethereum-contract-similarity}}
Determining exactly wich opcode sequences change would most likely require a lot of manual work.
To quickly and simply distinguish between opcode wich are likely to change and once that don't change I used the \code{solc-version-testset} \cite{solc-versions-testset} and reduced the codes to bytebags. Then I calculated an f-statistic \figref{ftest} for each opcode, using common source-code as grouping criterion and the count of the opcode as value.

\begin{figure*}[ht!]
  \centering
  \begin{math}
    F = \dfrac{\textrm{between group variability}}{\textrm{within group variability}}
  \end{math}
  \caption{One-way ANOVA F-test statistic}
  \label{fig:ftest}
\end{figure*}

To define the \code{fStat} filter I selected to top 30 opcodes by f-statistic value, plus a few that never occurred or only in one group.

\begin{lstlisting}[style=pymd]
OPCODES = (
  # top 30 fStat values
  ADDRESS, LOG3, TIMESTAMP, ORIGIN, LOG4, SHA3, SWAP14, CALLDATASIZE,
  CALLDATACOPY, SIGNEXTEND, CALL, LOG2, RETURNDATASIZE, CALLER, EXTCODESIZE,
  JUMPI, STATICCALL, RETURNDATACOPY, GAS, DUP13, DUP5, DUP8, GASPRICE,
  SHR, PUSH4, ISZERO, DUP7, ADD, DUP9, MUL,
  # occurred in only one group
  XOR, CALLVALUE, DELEGATECALL, SELFDESTRUCT,
  # never occurred
  SAR, LOG0, CREATE,
)
\end{lstlisting}

\subsection{Tests}
I tested with the following pre-processing settings.

\begin{description}
  \item[raw] Tho whole code unprocessed.
  \item[fstSec] The first code section.
  \item[skel] The skeleton of the whole code.
  \item[fstSecSkel] The skeleton of the fist code section.
  \item[fStat] fstSecSkel filtered of the opcodes in the fStat filter by cutting the others out.
  \item[fStat0] fStat but instead of cutting out the other opcodes are set to zero.
\end{description}

\end{document}
