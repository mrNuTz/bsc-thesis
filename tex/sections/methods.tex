\documentclass[../main.tex]{subfiles}
\begin{document}

To obtain similarity scores I preprocessed the codes, calculated digests(hashes) and compared those digest via similarity measures. Following is a quick summary of the methods used in this work.

\subsection{Digest Methods}
The following methods where used to obtain digests from codes for quick comparison via the similarity measures.

\begin{description}[style=unboxed,leftmargin=0cm]%style=nextline]
  \item[fourbytes]
    Extraction of the set of fourbyte signatures used to identify the interface functions. \cite{ethutils}

  \item[bytebag]
    Counting all opcodes in the code to form a multiset or bag of byte-values, a bytebag. \cite{ethereum-contract-similarity}

  \item[size]
    Just the length of the code in bytes.

  \item[ssdeep]
    A Context Triggered Piecewise Hashing (CTPH) Function. \cite{kornblum2006identifying}

  \item[ppdeep]
    Slightly different implementation of ssdeep in pure python. \cite{ppdeep}

  \item[ppdeep\_mod]
    Modified version of ppdeep. \cite{ethereum-contract-similarity}

  \item[lzjd (LZJD - Lempel-Ziv Jaccard Distance)]
    Generates a compression dictionary. \cite{raff2018lempel}

  \item[jump (jumpHash)]
    A piecewise hash splitting by the \code{JUMPI} instruction opcode \code{0x57}. \cite{ethereum-contract-similarity}

  \item[bz (bzHash)]
    Also splits by \code{JUMPI} and calculate a compression-ratio for each piece. \cite{ethereum-contract-similarity}

  \item[lev (Levenshtein)]
    Levenshtein edit distance on the whole code. Only used with very small codes (e.g. \n{proxies}).
\end{description}

\subsection{Similarity Measures}
To compare the digests the following similarity measures where applied.

\begin{description}[style=unboxed]
  \item[Jaccard Index]
    Defined on two sets \(A, B\), the Jaccard Index \(J\) is the ratio of common entries to all entries.
    \begin{equation}
      J(A,B) = |A \cap B| / |A \cup B| \in [0,1]
      \label{eq:jaccard}
    \end{equation}

  \item[Levenshtein similarity]
    Based on the Levenshtein Distance.

  \item[Normalized Compression Distance (NCD)]
    NCD is a measure for how well two files co-compress. The more features two files have in common the shorter the result when compressing the concatenation of the two files.
\end{description}

\subsection{Pre-Processing Methods}
Because small changes in the codes, can cause big changes in the digests pre-processing aims the remove non-essential parts.

\begin{description}[style=unboxed]
  \item[Segment selection]
    Selecting e.g. only the first code segment, the actual contract.

  \item[Skeletonization]
    Setting argument, data and meta section bytes to zero.

  \item[Opcode filteringn]
    Filtering for more significant opcodes by setting the others to zero or cutting them out.
\end{description}

\end{document}
